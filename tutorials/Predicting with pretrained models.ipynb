{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will introduce how to load our pretrained models from huggingface model hub and make predictions using trained models. We will then explain the prediction outcomes and showcase some result manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- [Load Pretrained Models from the Hub](#load-pretrained-models-from-the-hub)\n",
    "- [Make Predictions](#make-predictions)\n",
    "    - [Prior to Making Predictions](#prior-to-making-predictions)\n",
    "    - [Individual Predictions and Evaluation](#individual-predictions-and-evaluation)\n",
    "    - [Batched Predictions and Evaluations](#batched-predictions-and-evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Models from the Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a direct continuation from our [previous tutorial](./Loading%20unicausal%20model.ipynb), we load our pre-trained configs, model, and tokenizer from the HuggingFace model hub. They will come in handy for prediction and save you much time and resources from training the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /home/jiatong/miniconda3/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/jiatong/miniconda3/lib/python3.8/site-packages (from seqeval) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/jiatong/miniconda3/lib/python3.8/site-packages (from seqeval) (1.23.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/jiatong/miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jiatong/miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/jiatong/miniconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval) (1.8.1)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies for later operations\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Config ###\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"tanfiona/unicausal\",\n",
      "  \"architectures\": [\n",
      "    \"BertForUnifiedCRBase\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29000\n",
      "}\n",
      "\n",
      "### Model ###\n",
      "BertForUnifiedCRBase(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(29000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (classifier1): Linear(in_features=773, out_features=5, bias=True)\n",
      "  (classifier2): Linear(in_features=778, out_features=5, bias=True)\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (seq_classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "### Tokenizer ###\n",
      "PreTrainedTokenizerFast(name_or_path='tanfiona/unicausal', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "# import dependencies from HuggingFace transformers library\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from models.classifiers.modeling_bert import BertForUnifiedCRBase\n",
    "\n",
    "# declare label-to-id mapping and related model parameters\n",
    "label_to_id = {'B-C': 0, 'B-E': 1, 'I-C': 2, 'I-E': 3, 'O': 4}\n",
    "label_list = list(label_to_id.keys())\n",
    "num_labels = len(label_list)\n",
    "alpha = 1 \n",
    "cache_dir = None\n",
    "model_name_or_path = \"tanfiona/unicausal\" # model path at HuggingFace hub\n",
    "\n",
    "# initialize useful constructs for prediction\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path, num_labels=num_labels\n",
    ")\n",
    "# preview configurations\n",
    "print('### Config ###')\n",
    "print(config)\n",
    "model = BertForUnifiedCRBase.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    "    num_seq_labels=2,\n",
    "    loss_function='simple',\n",
    "    alpha=alpha\n",
    ")\n",
    "# preview model architecture\n",
    "print('### Model ###')\n",
    "print(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    cache_dir=cache_dir,\n",
    "    use_fast=True\n",
    ")\n",
    "# preview sentence tokenizer\n",
    "print('### Tokenizer ###')\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior to Making Predictions\n",
    "\n",
    "There are three tasks overall: sequence classification, span detection, and pair classification. We will go through examples for each task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the examples, here is some data loading and processing work that is necessary. Feel free to just run the cells without knowing the details. Examples follow immediately and they are more easily understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-38b075e54bc19cd6\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/jiatong/.cache/huggingface/datasets/csv/default-38b075e54bc19cd6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e9960921aa4c6fb12135052882abac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f31213be3642dcb6e261535215b96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba37b2736c7406f881c866a80d9214d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2089d8567af44f2b9aca3417c3bdfbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Preparation and house-keeping stuff - can just run and skip\n",
    "from transformers import default_data_collator\n",
    "from _datasets.unifiedcre import load_cre_dataset, available_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# load example datasets for validation\n",
    "span_datasets, seq_datasets, stats = load_cre_dataset(dataset_name=['altlex'], \\\n",
    "            do_train_val=True, do_train=False, data_dir='../data')\n",
    "\n",
    "# hardcode attributes for dataset processing\n",
    "PADDING_DICT = {\n",
    "    'input_ids': 0,\n",
    "    'tokens': '[PAD]',\n",
    "    'attention_mask': 0,\n",
    "    'labels': -100,\n",
    "    'label': -100,\n",
    "    'ce_tags': -100,\n",
    "    'ce_tags1': -100,\n",
    "    'ce_tags2': -100,\n",
    "    'token_type_ids': 0\n",
    "    }\n",
    "\n",
    "padding = \"max_length\" # defaults to pad to max length, in this case 128.\n",
    "max_seq_length = 128\n",
    "text_column_name = \"text\"\n",
    "span_label_column_name = \"ce_tags\"\n",
    "seq_label_column_name = \"label\"\n",
    "span_structure_source = list(span_datasets.keys())[0]\n",
    "seq_structure_source = list(seq_datasets.keys())[0]\n",
    "features = span_datasets[span_structure_source].features\n",
    "\n",
    "# aux function for tokenizing raw sequence texts\n",
    "def tokenize_and_add_tags(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        max_length=max_seq_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        is_split_into_words=False\n",
    "    )\n",
    "    dummy_span_labels = [] # missing spans / we don't want to train or evaluate on them\n",
    "    for ids in tokenized_inputs[\"input_ids\"]: # list of list\n",
    "        sequence_length = len(ids)\n",
    "        dummy_span_labels.append([PADDING_DICT[span_label_column_name]]*sequence_length)\n",
    "    \n",
    "    tokenized_inputs[span_label_column_name] = dummy_span_labels\n",
    "    tokenized_inputs[f\"{span_label_column_name}1\"] = dummy_span_labels\n",
    "    tokenized_inputs[f\"{span_label_column_name}2\"] = dummy_span_labels\n",
    "    tokenized_inputs[seq_label_column_name] = examples[seq_label_column_name]\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# process raw sequence datasets using defined functionality\n",
    "processed_seq_datasets = seq_datasets.map(\n",
    "    tokenize_and_add_tags,\n",
    "    batched=True,\n",
    "    # remove_columns=seq_datasets[seq_structure_source].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "# aux function for tokenizing span datasets\n",
    "def tokenize_and_align_tags(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        max_length=max_seq_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    tags, tags1, tags2 = [], [], []\n",
    "    for i, (label,label1,label2) in enumerate(zip(\\\n",
    "        examples[span_label_column_name],\n",
    "        examples[f\"{span_label_column_name}1\"],\n",
    "        examples[f\"{span_label_column_name}2\"],\n",
    "        )):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids, label_ids1, label_ids2 = [], [], []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(PADDING_DICT[span_label_column_name])\n",
    "                label_ids1.append(PADDING_DICT[f\"{span_label_column_name}1\"])\n",
    "                label_ids2.append(PADDING_DICT[f\"{span_label_column_name}2\"])\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "                label_ids1.append(label_to_id[label1[word_idx]])\n",
    "                label_ids2.append(label_to_id[label2[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to the current label\n",
    "            else:\n",
    "                label_ids.append(PADDING_DICT[span_label_column_name])\n",
    "                label_ids1.append(PADDING_DICT[f\"{span_label_column_name}1\"])\n",
    "                label_ids2.append(PADDING_DICT[f\"{span_label_column_name}2\"])\n",
    "            previous_word_idx = word_idx\n",
    "        tags.append(label_ids)\n",
    "        tags1.append(label_ids1)\n",
    "        tags2.append(label_ids2)\n",
    "    \n",
    "    tokenized_inputs[span_label_column_name] = tags\n",
    "    tokenized_inputs[f\"{span_label_column_name}1\"] = tags1\n",
    "    tokenized_inputs[f\"{span_label_column_name}2\"] = tags2\n",
    "    tokenized_inputs[seq_label_column_name] = examples[seq_label_column_name]\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "# process raw span datasets using defined functionality\n",
    "processed_span_datasets = span_datasets.map(\n",
    "    tokenize_and_align_tags,\n",
    "    batched=True,\n",
    "    remove_columns=span_datasets[span_structure_source].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Predictions and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will show some individual examples for each of the three tasks, before getting to batched predictions whose results are used to calculate evaluation metrics, such as accuracy or f1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sequence classification\n",
    "print('##### Sequence Classification Individual Example #####')\n",
    "example_texts = processed_seq_datasets['seq_validation']['text'][:16]\n",
    "true_labels = processed_seq_datasets['seq_validation']['label'][:16]\n",
    "data_collator = default_data_collator\n",
    "eval_pspan_dataloader = DataLoader(\n",
    "    processed_seq_datasets['seq_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=16\n",
    ")\n",
    "for (_, batch) in enumerate(eval_pspan_dataloader):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    predictions = model(**batch)\n",
    "    break\n",
    "\n",
    "for i in range(16):\n",
    "    print(f'Input text #{i+1}:',example_texts[i])\n",
    "    print('\\t [ predicted outcome:',predictions.seq_logits[i].argmax(dim=-1).tolist(),'vs actual outcome:',true_labels[i],']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a classification problem, we may compute metrics such as accuracy, precision, recall, and f1 scores to evaluate model performance, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiatong/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6875, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = true_labels\n",
    "    preds = predictions.seq_logits.argmax(dim=-1).tolist() \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    \n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "      'precision': prec,\n",
    "      'recall': recall,\n",
    "      'f1': f1,\n",
    "    }\n",
    "\n",
    "compute_metrics(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition:\n",
    "```\n",
    "    accuracy = (TP + TN) / N\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + TN)\n",
    "    f1 = 2*precision*recall / (precision + recall)\n",
    "```\n",
    "where `TP` is True Positive, `FP` is False Positive, `TN` is True Negative, `FN` is False Negative, and `N` is `(TP+FP+TN+FN)`.\n",
    "All metrics, including accuracy, precisiomn, recall, and f1, follow 'the higher, the better' rule. f1 score is the harmonic mean of precision and recall score, which balances Type I and Type II errors simultaneously, namely, it punishs cases where a sentence actually contains causal relation but classified as non-causal, as well as the cases where a sentence is not causal but misclassified as causal.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Pair Classification Individual Examples #####\n",
      "Input text #1: <ARG1>The Bhopal disaster , also referred to</ARG1> as <ARG0>the Bhopal gas tragedy , was a gas leak incident in India , considered the world 's worst industrial disaster .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #2: <ARG1>In addition , several vent gas scrubbers had been out of service as well</ARG1> as <ARG0>the steam boiler , intended to clean the pipes .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #3: <ARG1>Union Carbide organized a team of international medical experts ,</ARG1> as <ARG0>well as supplies and equipment , to work with the local Bhopal medical community , and the UCC technical team began assessing the cause of the gas leak .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #4: <ARG1>Following an appeal of this decision , the U.S. Court of Appeals affirmed the transfer , judging , in January 1987 , that UCIL was a `` separate entity , owned , managed</ARG1> and <ARG0>operated exclusively by Indian citizens in India '' .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #5: <ARG0>The U.S. Supreme Court refused to hear an appeal of the decision of the lower federal courts in October 1993 ,</ARG0> meaning <ARG1>that victims of the Bhopal disaster could not seek damages in a U.S. court .</ARG1>\n",
      "\t # predicted outcome: 1 vs actual outcome: 1\n",
      "Input text #6: <ARG1>It sought damages for personal injury , medical monitoring and injunctive relief in the form of clean-up of the drinking water supplies</ARG1> for <ARG0>residential areas near the Bhopal plant .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #7: <ARG1>When UCC wanted to sell its shares in UCIL , it was directed by the Supreme Court to finance a 500-bed hospital</ARG1> for <ARG0>the medical care of the survivors .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n",
      "Input text #8: <ARG1>On 8 June 2012 , the Centre</ARG1> for <ARG0>incineration of toxic Bhopal waste agreed to pay to dispose of UCIL chemical plants waste in Germany .</ARG0>\n",
      "\t # predicted outcome: 0 vs actual outcome: 0\n"
     ]
    }
   ],
   "source": [
    "# For pair classification\n",
    "print('##### Pair Classification Individual Examples #####')\n",
    "example_texts = processed_seq_datasets['pair_validation']['text'][:8]\n",
    "true_labels = processed_seq_datasets['pair_validation']['label'][:8]\n",
    "data_collator = default_data_collator\n",
    "eval_pspan_dataloader = DataLoader(\n",
    "    processed_seq_datasets['pair_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "for (_, batch) in enumerate(eval_pspan_dataloader):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    predictions = model(**batch)\n",
    "    break\n",
    "\n",
    "for i in range(8):\n",
    "    print(f'Input text #{i+1}:',example_texts[i])\n",
    "    print('\\t # predicted outcome:',predictions.seq_logits[i].argmax(dim=-1).tolist(),'vs actual outcome:',true_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate pair classification outcomes\n",
    "compute_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Span Detection Individual Examples #####\n",
      "Only first ten predicted tokens are printed.\n",
      "Input example #1\n",
      "\t predicted tag1: [3, 0, 2, 2, 2, 2, 2, 2, 2, 2] vs actual tag1: [-100, 0, 2, -100, -100, -100, 2, 2, 2, 2]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, -100, -100, -100, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, -100, -100, -100, 4, 4, 4, 4]\n",
      "Input example #2\n",
      "\t predicted tag1: [3, 4, 4, 4, 4, 4, 4, 0, 2, 2] vs actual tag1: [-100, 0, 2, 2, 2, 4, 4, 1, 3, 3]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Input example #3\n",
      "\t predicted tag1: [3, 4, 4, 4, 2, 1, 3, 3, 3, 3] vs actual tag1: [-100, 0, 2, 4, 1, 3, 3, 3, 3, 3]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Input example #4\n",
      "\t predicted tag1: [2, 1, 3, 3, 4, 4, 4, 0, 2, 2] vs actual tag1: [-100, 0, 2, 2, 4, 4, 4, 1, 3, 3]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Input example #5\n",
      "\t predicted tag1: [4, 1, 4, 3, 3, 3, 3, 3, 3, 3] vs actual tag1: [-100, 1, 3, 3, 3, 3, 3, -100, -100, 3]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, -100, -100, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, -100, -100, 4]\n",
      "Input example #6\n",
      "\t predicted tag1: [4, 4, 4, 4, 4, 1, 1, 3, 3, 3] vs actual tag1: [-100, 0, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 1] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Input example #7\n",
      "\t predicted tag1: [3, 0, 4, 1, 2, 2, 3, 1, 3, 3] vs actual tag1: [-100, 0, 2, 1, 3, 3, 3, 3, 3, 3]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Input example #8\n",
      "\t predicted tag1: [3, 0, 2, 2, 2, 4, 4, 4, 1, 3] vs actual tag1: [-100, 1, 3, 3, 4, 4, 4, 4, 0, 2]\n",
      "\t predicted tag2: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag2: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "\t predicted tag3: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4] vs actual tag3: [-100, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# For span detection\n",
    "print('##### Span Detection Individual Examples #####')\n",
    "example_tags1 = processed_span_datasets['span_validation']['ce_tags'][:8]\n",
    "example_tags2 = processed_span_datasets['span_validation']['ce_tags1'][:8]\n",
    "example_tags3 = processed_span_datasets['span_validation']['ce_tags2'][:8]\n",
    "true_labels = processed_span_datasets['span_validation']['label'][:8]\n",
    "data_collator = default_data_collator\n",
    "eval_pspan_dataloader = DataLoader(\n",
    "    processed_span_datasets['span_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "for (_, batch) in enumerate(eval_pspan_dataloader):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    predictions = model(**batch)\n",
    "    break\n",
    "\n",
    "print('Only first ten predicted tokens are printed.')\n",
    "\n",
    "for i in range(8):\n",
    "    print(f'Input example #{i+1}')\n",
    "    print('\\t predicted tag1:',predictions.tok_logits[i].argmax(dim=-1).tolist()[:10],'vs actual tag1:',example_tags1[i][:10])\n",
    "    print('\\t predicted tag2:',predictions.tok_logits1[i].argmax(dim=-1).tolist()[:10],'vs actual tag2:',example_tags2[i][:10])\n",
    "    print('\\t predicted tag3:',predictions.tok_logits2[i].argmax(dim=-1).tolist()[:10],'vs actual tag3:',example_tags3[i][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for span detection task\n",
    "def compute_metrics(pred):\n",
    "    labels = example_tags1 + example_tags2 + example_tags3\n",
    "    preds = predictions.tok_logits.argmax(dim=-1).tolist() + predictions.tok_logits1.argmax(dim=-1).tolist() + predictions.tok_logits2.argmax(dim=-1).tolist()\n",
    "\n",
    "    cancat_labels = []\n",
    "    cancat_preds = []\n",
    "    for label in labels:\n",
    "      cancat_labels.extend(label[:10])\n",
    "    for pred in preds:\n",
    "      cancat_preds.extend(pred[:10])\n",
    "    acc = accuracy_score(cancat_labels, cancat_preds, )\n",
    "    prec = precision_score(cancat_labels, cancat_preds, average='weighted')\n",
    "    recall = recall_score(cancat_labels, cancat_preds, average='weighted')\n",
    "    f1 = f1_score(cancat_labels, cancat_preds, average='weighted')\n",
    "    \n",
    "    cm = confusion_matrix(cancat_labels, cancat_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "      'precision': prec,\n",
    "      'recall': recall,\n",
    "      'f1': f1,\n",
    "    }\n",
    "\n",
    "compute_metrics(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched Predictions\n",
    "Below is the actual batched prediction that is used during training. Metrics are computed and printed in the second last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make pytorch dataloader objects for model prediction\n",
    "# use default data collator as padding is already done at max length\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# define dataloaders for prediction\n",
    "eval_dataset = processed_span_datasets['span_validation']\n",
    "\n",
    "# for span detection\n",
    "eval_pspan_dataloader = DataLoader(\n",
    "    eval_dataset, \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    "    )\n",
    "eval_pspan_corpus_col = span_datasets[\"span_validation\"][\"corpus\"]\n",
    "eval_pspan_unique_corpus = list(set(eval_pspan_corpus_col))\n",
    "\n",
    "# for sequence classification\n",
    "eval_aseq_dataloader = DataLoader(\n",
    "    processed_seq_datasets['seq_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "eval_aseq_corpus_col = seq_datasets[\"seq_validation\"][\"corpus\"]\n",
    "eval_aseq_unique_corpus = list(set(eval_aseq_corpus_col+eval_pspan_unique_corpus))\n",
    "\n",
    "# for pair classification\n",
    "eval_apair_dataloader = DataLoader(\n",
    "    processed_seq_datasets['pair_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "eval_apair_corpus_col = seq_datasets[\"pair_validation\"][\"corpus\"]\n",
    "eval_apair_unique_corpus = list(set(eval_apair_corpus_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction results saved here\n",
    "import torch\n",
    "\n",
    "all_preds, all_refs = [], []\n",
    "all_seq_preds, all_seq_refs = [], []\n",
    "all_pair_preds, all_pair_refs = [], []\n",
    "device = torch.device('cpu')\n",
    "\n",
    "def get_labels(predictions, references, ignore_ids=-100, remove_if_no_ce=True):\n",
    "    # Transform predictions and references tensors to numpy arrays\n",
    "    if device.type == \"cpu\":\n",
    "        y_pred = predictions.detach().clone().numpy()\n",
    "        y_true = references.detach().clone().numpy()\n",
    "    else:\n",
    "        y_pred = predictions.detach().cpu().clone().numpy()\n",
    "        y_true = references.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    # Remove if all are 'O' (dummy examples)\n",
    "    true_predictions, true_labels = [], []\n",
    "    for pred, gold_label in zip(y_pred, y_true):\n",
    "        true_p, true_l = [], []\n",
    "        for (p, l) in zip(pred, gold_label):\n",
    "            if l != ignore_ids:\n",
    "                true_p.append(label_list[p])\n",
    "                true_l.append(label_list[l])\n",
    "        if len(set(true_l))==1 and true_l[0]=='O' and remove_if_no_ce: # all dummy values\n",
    "            # drop these examples, append empties for alignment to index\n",
    "            true_predictions.append([])\n",
    "            true_labels.append([])\n",
    "        else:\n",
    "            true_predictions.append(true_p)\n",
    "            true_labels.append(true_l)\n",
    "\n",
    "    return true_predictions, true_labels\n",
    "\n",
    "def format(predictions, labels, remove_if_no_ce=True):\n",
    "    return get_labels(predictions, labels, PADDING_DICT[span_label_column_name], remove_if_no_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running prediction *****\n",
      "  Num seq examples = 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:21<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# sequence classification\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "metric = {d:load_metric('seqeval') for d in eval_pspan_unique_corpus+['all']}\n",
    "seq_metric = {d:load_metric('../utils/seq_metrics.py') for d in eval_aseq_unique_corpus+['all']}\n",
    "pair_metric = {d:load_metric('../utils/seq_metrics.py') for d in eval_apair_unique_corpus+['all']} \n",
    "\n",
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num seq examples = {len(eval_aseq_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_aseq_dataloader)):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "    # Get Seq Predictions & References\n",
    "    seq_preds = outputs.seq_logits.argmax(dim=-1).detach().cpu().clone().tolist()\n",
    "    seq_refs = batch[seq_label_column_name].detach().cpu().clone().tolist()\n",
    "\n",
    "    # Add to metrics\n",
    "    seq_metric['all'].add_batch(\n",
    "        predictions=seq_preds,\n",
    "        references=seq_refs\n",
    "    )\n",
    "\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_aseq_corpus_col[step*8:(step+1)*8] # batch_size=8\n",
    "    for i,d in enumerate(corps):\n",
    "        seq_metric[d].add(\n",
    "            prediction=seq_preds[i],\n",
    "            reference=seq_refs[i],\n",
    "        )\n",
    "    \n",
    "    # Store predictions\n",
    "    all_seq_preds.extend(seq_preds)\n",
    "    all_seq_refs.extend(seq_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For span detection tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running prediction *****\n",
      "  Num span examples = 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num span examples = {len(eval_pspan_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_pspan_dataloader)):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    # Get Span Predictions & References\n",
    "    preds, refs = format(\n",
    "        predictions=outputs.tok_logits.argmax(dim=-1), \n",
    "        labels=batch[span_label_column_name],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    preds1, refs1 = format(\n",
    "        predictions=outputs.tok_logits1.argmax(dim=-1), \n",
    "        labels=batch[f\"{span_label_column_name}1\"],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    preds2, refs2 = format(\n",
    "        predictions=outputs.tok_logits2.argmax(dim=-1), \n",
    "        labels=batch[f\"{span_label_column_name}2\"],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    \n",
    "    # Add to metrics\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds,\n",
    "        references=refs \n",
    "    ) # predictions and preferences are expected to be a nested list of labels, not label_ids\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds1,\n",
    "        references=refs1 \n",
    "    )\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds2,\n",
    "        references=refs2 \n",
    "    )\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_pspan_corpus_col[step*8:(step+1)*8] # batch_size = 8\n",
    "    for i,d in enumerate(corps):\n",
    "        metric[d].add(\n",
    "            prediction=preds[i],\n",
    "            reference=refs[i],\n",
    "        )\n",
    "        metric[d].add(\n",
    "            prediction=preds1[i],\n",
    "            reference=refs1[i],\n",
    "        )\n",
    "        metric[d].add(\n",
    "            prediction=preds2[i],\n",
    "            reference=refs2[i],\n",
    "        )\n",
    "\n",
    "    # Store predictions\n",
    "    all_preds.extend(preds)\n",
    "    all_refs.extend(refs)\n",
    "    all_preds.extend(preds1)\n",
    "    all_refs.extend(refs1)\n",
    "    all_preds.extend(preds2)\n",
    "    all_refs.extend(refs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pair classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running prediction *****\n",
      "  Num pair examples = 416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:28<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num pair examples = {len(eval_apair_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_apair_dataloader)):\n",
    "    batch['label'] = batch['labels'].clone()\n",
    "    del batch['labels']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    # Get Seq Predictions & References\n",
    "    seq_preds = outputs.seq_logits.argmax(dim=-1).detach().cpu().clone().tolist()\n",
    "    seq_refs = batch[seq_label_column_name].detach().cpu().clone().tolist()\n",
    "\n",
    "    # Add to metrics\n",
    "    pair_metric['all'].add_batch(\n",
    "        predictions=seq_preds,\n",
    "        references=seq_refs\n",
    "    )\n",
    "\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_apair_corpus_col[step*8:(step+1)*8] # batch-size=8\n",
    "    for i,d in enumerate(corps):\n",
    "        pair_metric[d].add(\n",
    "            prediction=seq_preds[i],\n",
    "            reference=seq_refs[i],\n",
    "        )\n",
    "    \n",
    "    # Store predictions\n",
    "    all_pair_preds.extend(seq_preds)\n",
    "    all_pair_refs.extend(seq_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span predictions for 'altlex' :\n",
      "\t precision: 0.000\n",
      "\t recall: 0.000\n",
      "\t f1: 0.000\n",
      "\t accuracy: 0.000\n",
      "seq predictions for 'altlex' :\n",
      "\t n: 286.000\n",
      "\t accuracy: 0.822\n",
      "\t matthews_correlation: 0.000\n",
      "\t macro_precision: 0.500\n",
      "\t macro_recall: 0.411\n",
      "\t macro_f1: 0.451\n",
      "\t weighted_precision: 1.000\n",
      "\t weighted_recall: 0.822\n",
      "\t weighted_f1: 0.902\n",
      "\t binary_precision: 0.000\n",
      "\t binary_recall: 0.000\n",
      "\t binary_f1: 0.000\n",
      "pair predictions for 'altlex' :\n",
      "\t n: 416.000\n",
      "\t accuracy: 0.882\n",
      "\t matthews_correlation: 0.715\n",
      "\t macro_precision: 0.875\n",
      "\t macro_recall: 0.840\n",
      "\t macro_f1: 0.855\n",
      "\t weighted_precision: 0.881\n",
      "\t weighted_recall: 0.882\n",
      "\t weighted_f1: 0.879\n",
      "\t binary_precision: 0.861\n",
      "\t binary_recall: 0.732\n",
      "\t binary_f1: 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiatong/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jiatong/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jiatong/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate above predictions\n",
    "return_entity_level_metrics = False\n",
    "def compute_metrics(d='all'):\n",
    "    try:\n",
    "        results = metric[d].compute()\n",
    "        if return_entity_level_metrics:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {}\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "    except:\n",
    "        # No C-E true labels available\n",
    "        return {\n",
    "                \"precision\": 0,\n",
    "                \"recall\": 0,\n",
    "                \"f1\": 0,\n",
    "                \"accuracy\": 0,\n",
    "            }\n",
    "\n",
    "def pretty_print(metrics: dict):\n",
    "    for (k,v) in metrics.items():\n",
    "        print('\\t',\"{}: {:.3f}\".format(k, v if not isinstance(v, tuple) else v[0]))\n",
    "\n",
    "for d in eval_pspan_unique_corpus:\n",
    "    span_eval_metric = compute_metrics(d)\n",
    "    print(f\"span predictions for '{d}' :\")\n",
    "    pretty_print(span_eval_metric)\n",
    "for d in list(set(eval_pspan_unique_corpus+eval_aseq_unique_corpus)):\n",
    "    seq_eval_metric = seq_metric[d].compute()\n",
    "    print(f\"seq predictions for '{d}' :\")\n",
    "    pretty_print(seq_eval_metric)\n",
    "for d in eval_apair_unique_corpus:\n",
    "    pair_eval_metric = pair_metric[d].compute()\n",
    "    print(f\"pair predictions for '{d}' :\")\n",
    "    pretty_print(pair_eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the first [loading CRE dataset notebook](./Loading%20CRE%20datasets.ipynb), all three tasks are ultimately treated as classifications. Thus, we may use accuracy, precision, recall, and f1 scores to evaluate model performances. They follow their traditional definitions and can be easily looked up online. For explanations of weighted, macro, and micro scores, you may find this [source](https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f#:~:text=The%20weighted%2Daveraged%20F1%20score,the%20class%20in%20the%20dataset.) useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
