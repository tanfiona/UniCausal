{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will introduce how to load our pretrained models from huggingface model hub and make predictions using trained models. We will then explain the prediction outcomes and showcase some result manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "1. [Load Pretrained Models from the Hub](#load-pretrained-models-from-the-hub)\n",
    "2. [Make Predictions](#make-predictions)\n",
    "2. [Evaluation Metrics and Results](#evaluation-metrics-and-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Models from the Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a direct continuation from our [previous tutorial](./Loading%20unicausal%20model.ipynb), we load our pre-trained configs, model, and tokenizer from the HuggingFace model hub. They will come in handy for prediction and save you much time and resources from training the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies for later operations\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Config ###\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"tanfiona/unicausal\",\n",
      "  \"architectures\": [\n",
      "    \"BertForUnifiedCRBase\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29000\n",
      "}\n",
      "\n",
      "### Model ###\n",
      "BertForUnifiedCRBase(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(29000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (classifier1): Linear(in_features=773, out_features=5, bias=True)\n",
      "  (classifier2): Linear(in_features=778, out_features=5, bias=True)\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (seq_classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "### Tokenizer ###\n",
      "PreTrainedTokenizerFast(name_or_path='tanfiona/unicausal', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "# import dependencies from HuggingFace transformers library\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from models.classifiers.modeling_bert import BertForUnifiedCRBase\n",
    "\n",
    "# declare label-to-id mapping and related model parameters\n",
    "label_to_id = {'B-C': 0, 'B-E': 1, 'I-C': 2, 'I-E': 3, 'O': 4}\n",
    "label_list = list(label_to_id.keys())\n",
    "num_labels = len(label_list)\n",
    "alpha = 1 \n",
    "cache_dir = None\n",
    "model_name_or_path = \"tanfiona/unicausal\" # model path at HuggingFace hub\n",
    "\n",
    "# initialize useful constructs for prediction\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path, num_labels=num_labels\n",
    ")\n",
    "# preview configurations\n",
    "print('### Config ###')\n",
    "print(config)\n",
    "model = BertForUnifiedCRBase.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    "    num_seq_labels=2,\n",
    "    loss_function='simple',\n",
    "    alpha=alpha\n",
    ")\n",
    "# preview model architecture\n",
    "print('### Model ###')\n",
    "print(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    cache_dir=cache_dir,\n",
    "    use_fast=True\n",
    ")\n",
    "# preview sentence tokenizer\n",
    "print('### Tokenizer ###')\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "There are three tasks overall: sequence classification, span detection, and pair classification. We will go through examples for each task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to the examples, here is some data loading and processing work that is necessary. Feel free to just run the cells without knowing the details. Examples follow immediately and they are more easily understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-38b075e54bc19cd6\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/jiatong/.cache/huggingface/datasets/csv/default-38b075e54bc19cd6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44d3f6958c94ef4917bc8ad2656cbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc200a1202c044a183d0807298598377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0cc07c728f411e88ed728ea439a61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7151ed3523a04ceb848c935e937d9c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Preparation and house-keeping stuff - can just run and skip\n",
    "from transformers import default_data_collator\n",
    "from _datasets.unifiedcre import load_cre_dataset, available_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# load example datasets for validation\n",
    "span_datasets, seq_datasets, stats = load_cre_dataset(dataset_name=['altlex'], \\\n",
    "            do_train_val=True, do_train=False, data_dir='../data')\n",
    "\n",
    "# hardcode attributes for dataset processing\n",
    "PADDING_DICT = {\n",
    "    'input_ids': 0,\n",
    "    'tokens': '[PAD]',\n",
    "    'attention_mask': 0,\n",
    "    'labels': -100,\n",
    "    'label': -100,\n",
    "    'ce_tags': -100,\n",
    "    'ce_tags1': -100,\n",
    "    'ce_tags2': -100,\n",
    "    'token_type_ids': 0\n",
    "    }\n",
    "\n",
    "padding = \"max_length\" # defaults to pad to max length, in this case 128.\n",
    "max_seq_length = 128\n",
    "text_column_name = \"text\"\n",
    "span_label_column_name = \"ce_tags\"\n",
    "seq_label_column_name = \"label\"\n",
    "span_structure_source = list(span_datasets.keys())[0]\n",
    "seq_structure_source = list(seq_datasets.keys())[0]\n",
    "features = span_datasets[span_structure_source].features\n",
    "\n",
    "# aux function for tokenizing raw sequence texts\n",
    "def tokenize_and_add_tags(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        max_length=max_seq_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        is_split_into_words=False\n",
    "    )\n",
    "    dummy_span_labels = [] # missing spans / we don't want to train or evaluate on them\n",
    "    for ids in tokenized_inputs[\"input_ids\"]: # list of list\n",
    "        sequence_length = len(ids)\n",
    "        dummy_span_labels.append([PADDING_DICT[span_label_column_name]]*sequence_length)\n",
    "    \n",
    "    tokenized_inputs[span_label_column_name] = dummy_span_labels\n",
    "    tokenized_inputs[f\"{span_label_column_name}1\"] = dummy_span_labels\n",
    "    tokenized_inputs[f\"{span_label_column_name}2\"] = dummy_span_labels\n",
    "    tokenized_inputs[seq_label_column_name] = examples[seq_label_column_name]\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# process raw sequence datasets using defined functionality\n",
    "processed_seq_datasets = seq_datasets.map(\n",
    "    tokenize_and_add_tags,\n",
    "    batched=True,\n",
    "    remove_columns=seq_datasets[seq_structure_source].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "# aux function for tokenizing span datasets\n",
    "def tokenize_and_align_tags(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        max_length=max_seq_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    tags, tags1, tags2 = [], [], []\n",
    "    for i, (label,label1,label2) in enumerate(zip(\\\n",
    "        examples[span_label_column_name],\n",
    "        examples[f\"{span_label_column_name}1\"],\n",
    "        examples[f\"{span_label_column_name}2\"],\n",
    "        )):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids, label_ids1, label_ids2 = [], [], []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(PADDING_DICT[span_label_column_name])\n",
    "                label_ids1.append(PADDING_DICT[f\"{span_label_column_name}1\"])\n",
    "                label_ids2.append(PADDING_DICT[f\"{span_label_column_name}2\"])\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "                label_ids1.append(label_to_id[label1[word_idx]])\n",
    "                label_ids2.append(label_to_id[label2[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to the current label\n",
    "            else:\n",
    "                label_ids.append(PADDING_DICT[span_label_column_name])\n",
    "                label_ids1.append(PADDING_DICT[f\"{span_label_column_name}1\"])\n",
    "                label_ids2.append(PADDING_DICT[f\"{span_label_column_name}2\"])\n",
    "            previous_word_idx = word_idx\n",
    "        tags.append(label_ids)\n",
    "        tags1.append(label_ids1)\n",
    "        tags2.append(label_ids2)\n",
    "    \n",
    "    tokenized_inputs[span_label_column_name] = tags\n",
    "    tokenized_inputs[f\"{span_label_column_name}1\"] = tags1\n",
    "    tokenized_inputs[f\"{span_label_column_name}2\"] = tags2\n",
    "    tokenized_inputs[seq_label_column_name] = examples[seq_label_column_name]\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "# process raw span datasets using defined functionality\n",
    "processed_span_datasets = span_datasets.map(\n",
    "    tokenize_and_align_tags,\n",
    "    batched=True,\n",
    "    remove_columns=span_datasets[span_structure_source].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make pytorch dataloader objects for model prediction\n",
    "# use default data collator as padding is already done at max length\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# define dataloaders for prediction\n",
    "eval_dataset = processed_span_datasets['span_validation']\n",
    "\n",
    "# for span detection\n",
    "eval_pspan_dataloader = DataLoader(\n",
    "    eval_dataset, \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    "    )\n",
    "eval_pspan_corpus_col = span_datasets[\"span_validation\"][\"corpus\"]\n",
    "eval_pspan_unique_corpus = list(set(eval_pspan_corpus_col))\n",
    "\n",
    "# for sequence classification\n",
    "eval_aseq_dataloader = DataLoader(\n",
    "    processed_seq_datasets['seq_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "eval_aseq_corpus_col = seq_datasets[\"seq_validation\"][\"corpus\"]\n",
    "eval_aseq_unique_corpus = list(set(eval_aseq_corpus_col+eval_pspan_unique_corpus))\n",
    "\n",
    "# for pair classification\n",
    "eval_apair_dataloader = DataLoader(\n",
    "    processed_seq_datasets['pair_validation'], \n",
    "    shuffle=False, collate_fn=data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "eval_apair_corpus_col = seq_datasets[\"pair_validation\"][\"corpus\"]\n",
    "eval_apair_unique_corpus = list(set(eval_apair_corpus_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction results saved here\n",
    "all_preds, all_refs = [], []\n",
    "all_seq_preds, all_seq_refs = [], []\n",
    "all_pair_preds, all_pair_refs = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run predictions on sequence classification examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running prediction *****\n",
      "  Num seq examples = 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0]), 'input_ids': tensor([[  101,  1109,   139,  ...,     0,     0,     0],\n",
      "        [  101,  1130,  1901,  ...,     0,     0,     0],\n",
      "        [  101,  1913,  8185,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1332, 16991,  ...,     0,     0,     0],\n",
      "        [  101,  1212,   129,  ...,     0,     0,     0],\n",
      "        [  101,  2091,   183,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'ce_tags': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]), 'ce_tags1': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]), 'ce_tags2': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sequence classification\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "metric = {d:load_metric('seqeval') for d in eval_pspan_unique_corpus+['all']}\n",
    "seq_metric = {d:load_metric('../utils/seq_metrics.py') for d in eval_aseq_unique_corpus+['all']}\n",
    "pair_metric = {d:load_metric('../utils/seq_metrics.py') for d in eval_apair_unique_corpus+['all']} \n",
    "\n",
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num seq examples = {len(eval_aseq_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_aseq_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        if step == 0:\n",
    "            print('input batch:',**batch)\n",
    "            print('output logits:',outputs.seq_logits)\n",
    "\n",
    "    # Get Seq Predictions & References\n",
    "    seq_preds = outputs.seq_logits.argmax(dim=-1).detach().cpu().clone().tolist()\n",
    "    seq_refs = batch[seq_label_column_name].detach().cpu().clone().tolist()\n",
    "\n",
    "    # Add to metrics\n",
    "    seq_metric['all'].add_batch(\n",
    "        predictions=seq_preds,\n",
    "        references=seq_refs\n",
    "    )\n",
    "\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_aseq_corpus_col[step*8:(step+1)*8] # batch_size=8\n",
    "    for i,d in enumerate(corps):\n",
    "        seq_metric[d].add(\n",
    "            prediction=seq_preds[i],\n",
    "            reference=seq_refs[i],\n",
    "        )\n",
    "    \n",
    "    # Store predictions\n",
    "    all_seq_preds.extend(seq_preds)\n",
    "    all_seq_refs.extend(seq_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For span detection tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num span examples = {len(eval_pspan_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_pspan_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        if step == 0:\n",
    "            print('input batch:',**batch)\n",
    "            print('output logits:',outputs.tok_logits)\n",
    "\n",
    "    # Get Span Predictions & References\n",
    "    preds, refs = format(\n",
    "        predictions=outputs.tok_logits.argmax(dim=-1), \n",
    "        labels=batch[span_label_column_name],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    preds1, refs1 = format(\n",
    "        predictions=outputs.tok_logits1.argmax(dim=-1), \n",
    "        labels=batch[f\"{span_label_column_name}1\"],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    preds2, refs2 = format(\n",
    "        predictions=outputs.tok_logits2.argmax(dim=-1), \n",
    "        labels=batch[f\"{span_label_column_name}2\"],\n",
    "        remove_if_no_ce=False\n",
    "        )\n",
    "    \n",
    "    # Get Seq Predictions & References\n",
    "    seq_preds = outputs.seq_logits.argmax(dim=-1).detach().cpu().clone().tolist()\n",
    "    seq_refs = batch[seq_label_column_name].detach().cpu().clone().tolist()\n",
    "    \n",
    "    # Add to metrics\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds,\n",
    "        references=refs \n",
    "    ) # predictions and preferences are expected to be a nested list of labels, not label_ids\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds1,\n",
    "        references=refs1 \n",
    "    )\n",
    "    metric['all'].add_batch(\n",
    "        predictions=preds2,\n",
    "        references=refs2 \n",
    "    )\n",
    "    seq_metric['all'].add_batch(\n",
    "        predictions=seq_preds,\n",
    "        references=seq_refs\n",
    "    )\n",
    "\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_pspan_corpus_col[step*args.per_device_eval_batch_size:(step+1)*args.per_device_eval_batch_size]\n",
    "    for i,d in enumerate(corps):\n",
    "        metric[d].add(\n",
    "            prediction=preds[i],\n",
    "            reference=refs[i],\n",
    "        )\n",
    "        metric[d].add(\n",
    "            prediction=preds1[i],\n",
    "            reference=refs1[i],\n",
    "        )\n",
    "        metric[d].add(\n",
    "            prediction=preds2[i],\n",
    "            reference=refs2[i],\n",
    "        )\n",
    "        seq_metric[d].add(\n",
    "            prediction=seq_preds[i],\n",
    "            reference=seq_refs[i],\n",
    "        )\n",
    "\n",
    "    # Store predictions\n",
    "    all_preds.extend(preds)\n",
    "    all_refs.extend(refs)\n",
    "    all_preds.extend(preds1)\n",
    "    all_refs.extend(refs1)\n",
    "    all_preds.extend(preds2)\n",
    "    all_refs.extend(refs2)\n",
    "    all_seq_preds.extend(seq_preds)\n",
    "    all_seq_refs.extend(seq_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***** Running prediction *****\")\n",
    "print(f\"  Num pair examples = {len(eval_apair_corpus_col)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for step, batch in enumerate(tqdm(eval_apair_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        if step == 0:\n",
    "            print('input batch:',**batch)\n",
    "            print('output logits:',outputs.seq_logits)\n",
    "\n",
    "    # Get Seq Predictions & References\n",
    "    seq_preds = outputs.seq_logits.argmax(dim=-1).detach().cpu().clone().tolist()\n",
    "    seq_refs = batch[seq_label_column_name].detach().cpu().clone().tolist()\n",
    "\n",
    "    # Add to metrics\n",
    "    pair_metric['all'].add_batch(\n",
    "        predictions=seq_preds,\n",
    "        references=seq_refs\n",
    "    )\n",
    "\n",
    "    # Add to metrics by dataset name\n",
    "    corps = eval_apair_corpus_col[step*8:(step+1)*8] # batch-size=8\n",
    "    for i,d in enumerate(corps):\n",
    "        pair_metric[d].add(\n",
    "            prediction=seq_preds[i],\n",
    "            reference=seq_refs[i],\n",
    "        )\n",
    "    \n",
    "    # Store predictions\n",
    "    all_pair_preds.extend(seq_preds)\n",
    "    all_pair_refs.extend(seq_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate above predictions\n",
    "for d in eval_pspan_unique_corpus+['all']:\n",
    "    eval_metric = compute_metrics(d)\n",
    "    print(f\"span predictions for '{d}' : {eval_metric}\")\n",
    "for d in list(set(eval_pspan_unique_corpus+eval_aseq_unique_corpus))+['all']:\n",
    "    eval_metric = seq_metric[d].compute()\n",
    "    print(f\"seq predictions for '{d}' : {eval_metric}\")\n",
    "for d in eval_apair_unique_corpus+['all']:\n",
    "    eval_metric = pair_metric[d].compute()\n",
    "    print(f\"pair predictions for '{d}' : {eval_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "* Explain F1 score\n",
    "* Print raw input sentences instead of tokenized sentences "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
